[
  {
    "objectID": "index.html#autonomous-command-optimization-network-acon",
    "href": "index.html#autonomous-command-optimization-network-acon",
    "title": "Research Papers",
    "section": "> Autonomous Command Optimization Network (ACON)",
    "text": "&gt; Autonomous Command Optimization Network (ACON)\n\nv1.0 via Multi-Arm Bandit -  Completed\nv2.0: Advanced Reinforcement Learning - In Progress"
  },
  {
    "objectID": "index.html#cognitive-optimization-workflow-intelligence-ciow",
    "href": "index.html#cognitive-optimization-workflow-intelligence-ciow",
    "title": "Research Papers",
    "section": "> Cognitive Optimization Workflow Intelligence (CIOW)",
    "text": "&gt; Cognitive Optimization Workflow Intelligence (CIOW)\n\nv1.0: Practical Implementation - Coming Soon"
  },
  {
    "objectID": "images/metrics_timeseries_H.html",
    "href": "images/metrics_timeseries_H.html",
    "title": "Research Home",
    "section": "",
    "text": "Time\nSeen\nAccepted\nAcceptance Rate (%)\n\n\n\n\n2025-08-28 17:00\n33\n3\n9.09\n\n\n2025-08-28 18:00\n0\n0\n0.00\n\n\n2025-08-28 19:00\n0\n0\n0.00\n\n\n2025-08-28 20:00\n0\n0\n0.00\n\n\n2025-08-28 21:00\n0\n0\n0.00\n\n\n2025-08-28 22:00\n0\n0\n0.00\n\n\n2025-08-28 23:00\n0\n0\n0.00\n\n\n2025-08-29 00:00\n0\n0\n0.00\n\n\n2025-08-29 01:00\n0\n0\n0.00\n\n\n2025-08-29 02:00\n0\n0\n0.00\n\n\n2025-08-29 03:00\n0\n0\n0.00\n\n\n2025-08-29 04:00\n0\n0\n0.00\n\n\n2025-08-29 05:00\n0\n0\n0.00\n\n\n2025-08-29 06:00\n0\n0\n0.00\n\n\n2025-08-29 07:00\n0\n0\n0.00\n\n\n2025-08-29 08:00\n0\n0\n0.00\n\n\n2025-08-29 09:00\n0\n0\n0.00\n\n\n2025-08-29 10:00\n0\n0\n0.00\n\n\n2025-08-29 11:00\n0\n0\n0.00\n\n\n2025-08-29 12:00\n0\n0\n0.00\n\n\n2025-08-29 13:00\n0\n0\n0.00\n\n\n2025-08-29 14:00\n0\n0\n0.00\n\n\n2025-08-29 15:00\n0\n0\n0.00\n\n\n2025-08-29 16:00\n0\n0\n0.00\n\n\n2025-08-29 17:00\n0\n0\n0.00\n\n\n2025-08-29 18:00\n0\n0\n0.00\n\n\n2025-08-29 19:00\n0\n0\n0.00\n\n\n2025-08-29 20:00\n0\n0\n0.00\n\n\n2025-08-29 21:00\n0\n0\n0.00\n\n\n2025-08-29 22:00\n0\n0\n0.00\n\n\n2025-08-29 23:00\n0\n0\n0.00\n\n\n2025-08-30 00:00\n0\n0\n0.00\n\n\n2025-08-30 01:00\n0\n0\n0.00\n\n\n2025-08-30 02:00\n0\n0\n0.00\n\n\n2025-08-30 03:00\n0\n0\n0.00\n\n\n2025-08-30 04:00\n0\n0\n0.00\n\n\n2025-08-30 05:00\n0\n0\n0.00\n\n\n2025-08-30 06:00\n0\n0\n0.00\n\n\n2025-08-30 07:00\n0\n0\n0.00\n\n\n2025-08-30 08:00\n0\n0\n0.00\n\n\n2025-08-30 09:00\n0\n0\n0.00\n\n\n2025-08-30 10:00\n0\n0\n0.00\n\n\n2025-08-30 11:00\n0\n0\n0.00\n\n\n2025-08-30 12:00\n0\n0\n0.00\n\n\n2025-08-30 13:00\n0\n0\n0.00\n\n\n2025-08-30 14:00\n0\n0\n0.00\n\n\n2025-08-30 15:00\n0\n0\n0.00\n\n\n2025-08-30 16:00\n0\n0\n0.00\n\n\n2025-08-30 17:00\n0\n0\n0.00\n\n\n2025-08-30 18:00\n0\n0\n0.00\n\n\n2025-08-30 19:00\n0\n0\n0.00\n\n\n2025-08-30 20:00\n0\n0\n0.00\n\n\n2025-08-30 21:00\n0\n0\n0.00\n\n\n2025-08-30 22:00\n0\n0\n0.00\n\n\n2025-08-30 23:00\n0\n0\n0.00\n\n\n2025-08-31 00:00\n0\n0\n0.00\n\n\n2025-08-31 01:00\n0\n0\n0.00\n\n\n2025-08-31 02:00\n0\n0\n0.00\n\n\n2025-08-31 03:00\n0\n0\n0.00\n\n\n2025-08-31 04:00\n0\n0\n0.00\n\n\n2025-08-31 05:00\n0\n0\n0.00\n\n\n2025-08-31 06:00\n0\n0\n0.00\n\n\n2025-08-31 07:00\n0\n0\n0.00\n\n\n2025-08-31 08:00\n0\n0\n0.00\n\n\n2025-08-31 09:00\n0\n0\n0.00\n\n\n2025-08-31 10:00\n0\n0\n0.00\n\n\n2025-08-31 11:00\n0\n0\n0.00\n\n\n2025-08-31 12:00\n0\n0\n0.00\n\n\n2025-08-31 13:00\n0\n0\n0.00\n\n\n2025-08-31 14:00\n0\n0\n0.00\n\n\n2025-08-31 15:00\n0\n0\n0.00\n\n\n2025-08-31 16:00\n0\n0\n0.00\n\n\n2025-08-31 17:00\n0\n0\n0.00\n\n\n2025-08-31 18:00\n0\n0\n0.00\n\n\n2025-08-31 19:00\n0\n0\n0.00\n\n\n2025-08-31 20:00\n0\n0\n0.00\n\n\n2025-08-31 21:00\n0\n0\n0.00\n\n\n2025-08-31 22:00\n0\n0\n0.00\n\n\n2025-08-31 23:00\n0\n0\n0.00\n\n\n2025-09-01 00:00\n0\n0\n0.00\n\n\n2025-09-01 01:00\n0\n0\n0.00\n\n\n2025-09-01 02:00\n0\n0\n0.00\n\n\n2025-09-01 03:00\n0\n0\n0.00\n\n\n2025-09-01 04:00\n0\n0\n0.00\n\n\n2025-09-01 05:00\n0\n0\n0.00\n\n\n2025-09-01 06:00\n0\n0\n0.00\n\n\n2025-09-01 07:00\n0\n0\n0.00\n\n\n2025-09-01 08:00\n0\n0\n0.00\n\n\n2025-09-01 09:00\n0\n0\n0.00\n\n\n2025-09-01 10:00\n0\n0\n0.00\n\n\n2025-09-01 11:00\n0\n0\n0.00\n\n\n2025-09-01 12:00\n0\n0\n0.00\n\n\n2025-09-01 13:00\n0\n0\n0.00\n\n\n2025-09-01 14:00\n0\n0\n0.00\n\n\n2025-09-01 15:00\n0\n0\n0.00\n\n\n2025-09-01 16:00\n0\n0\n0.00\n\n\n2025-09-01 17:00\n0\n0\n0.00\n\n\n2025-09-01 18:00\n0\n0\n0.00\n\n\n2025-09-01 19:00\n0\n0\n0.00\n\n\n2025-09-01 20:00\n0\n0\n0.00\n\n\n2025-09-01 21:00\n0\n0\n0.00\n\n\n2025-09-01 22:00\n0\n0\n0.00\n\n\n2025-09-01 23:00\n0\n0\n0.00\n\n\n2025-09-02 00:00\n0\n0\n0.00\n\n\n2025-09-02 01:00\n0\n0\n0.00\n\n\n2025-09-02 02:00\n0\n0\n0.00\n\n\n2025-09-02 03:00\n0\n0\n0.00\n\n\n2025-09-02 04:00\n0\n0\n0.00\n\n\n2025-09-02 05:00\n0\n0\n0.00\n\n\n2025-09-02 06:00\n0\n0\n0.00\n\n\n2025-09-02 07:00\n0\n0\n0.00\n\n\n2025-09-02 08:00\n0\n0\n0.00\n\n\n2025-09-02 09:00\n0\n0\n0.00\n\n\n2025-09-02 10:00\n0\n0\n0.00\n\n\n2025-09-02 11:00\n0\n0\n0.00\n\n\n2025-09-02 12:00\n0\n0\n0.00\n\n\n2025-09-02 13:00\n0\n0\n0.00\n\n\n2025-09-02 14:00\n0\n0\n0.00\n\n\n2025-09-02 15:00\n0\n0\n0.00\n\n\n2025-09-02 16:00\n0\n0\n0.00\n\n\n2025-09-02 17:00\n0\n0\n0.00\n\n\n2025-09-02 18:00\n0\n0\n0.00\n\n\n2025-09-02 19:00\n0\n0\n0.00\n\n\n2025-09-02 20:00\n0\n0\n0.00\n\n\n2025-09-02 21:00\n0\n0\n0.00\n\n\n2025-09-02 22:00\n0\n0\n0.00\n\n\n2025-09-02 23:00\n0\n0\n0.00\n\n\n2025-09-03 00:00\n0\n0\n0.00\n\n\n2025-09-03 01:00\n0\n0\n0.00\n\n\n2025-09-03 02:00\n0\n0\n0.00\n\n\n2025-09-03 03:00\n0\n0\n0.00\n\n\n2025-09-03 04:00\n0\n0\n0.00\n\n\n2025-09-03 05:00\n0\n0\n0.00\n\n\n2025-09-03 06:00\n0\n0\n0.00\n\n\n2025-09-03 07:00\n0\n0\n0.00\n\n\n2025-09-03 08:00\n0\n0\n0.00\n\n\n2025-09-03 09:00\n0\n0\n0.00\n\n\n2025-09-03 10:00\n0\n0\n0.00\n\n\n2025-09-03 11:00\n0\n0\n0.00\n\n\n2025-09-03 12:00\n0\n0\n0.00\n\n\n2025-09-03 13:00\n0\n0\n0.00\n\n\n2025-09-03 14:00\n0\n0\n0.00\n\n\n2025-09-03 15:00\n0\n0\n0.00\n\n\n2025-09-03 16:00\n0\n0\n0.00\n\n\n2025-09-03 17:00\n0\n0\n0.00\n\n\n2025-09-03 18:00\n0\n0\n0.00\n\n\n2025-09-03 19:00\n0\n0\n0.00\n\n\n2025-09-03 20:00\n0\n0\n0.00\n\n\n2025-09-03 21:00\n0\n0\n0.00\n\n\n2025-09-03 22:00\n0\n0\n0.00\n\n\n2025-09-03 23:00\n0\n0\n0.00\n\n\n2025-09-04 00:00\n0\n0\n0.00\n\n\n2025-09-04 01:00\n0\n0\n0.00\n\n\n2025-09-04 02:00\n0\n0\n0.00\n\n\n2025-09-04 03:00\n0\n0\n0.00\n\n\n2025-09-04 04:00\n0\n0\n0.00\n\n\n2025-09-04 05:00\n0\n0\n0.00\n\n\n2025-09-04 06:00\n0\n0\n0.00\n\n\n2025-09-04 07:00\n0\n0\n0.00\n\n\n2025-09-04 08:00\n0\n0\n0.00\n\n\n2025-09-04 09:00\n0\n0\n0.00\n\n\n2025-09-04 10:00\n0\n0\n0.00\n\n\n2025-09-04 11:00\n0\n0\n0.00\n\n\n2025-09-04 12:00\n0\n0\n0.00\n\n\n2025-09-04 13:00\n0\n0\n0.00\n\n\n2025-09-04 14:00\n0\n0\n0.00\n\n\n2025-09-04 15:00\n0\n0\n0.00\n\n\n2025-09-04 16:00\n0\n0\n0.00\n\n\n2025-09-04 17:00\n0\n0\n0.00\n\n\n2025-09-04 18:00\n0\n0\n0.00\n\n\n2025-09-04 19:00\n0\n0\n0.00\n\n\n2025-09-04 20:00\n0\n0\n0.00\n\n\n2025-09-04 21:00\n0\n0\n0.00\n\n\n2025-09-04 22:00\n0\n0\n0.00\n\n\n2025-09-04 23:00\n0\n0\n0.00\n\n\n2025-09-05 00:00\n0\n0\n0.00\n\n\n2025-09-05 01:00\n0\n0\n0.00\n\n\n2025-09-05 02:00\n0\n0\n0.00\n\n\n2025-09-05 03:00\n0\n0\n0.00\n\n\n2025-09-05 04:00\n0\n0\n0.00\n\n\n2025-09-05 05:00\n0\n0\n0.00\n\n\n2025-09-05 06:00\n0\n0\n0.00\n\n\n2025-09-05 07:00\n0\n0\n0.00\n\n\n2025-09-05 08:00\n0\n0\n0.00\n\n\n2025-09-05 09:00\n0\n0\n0.00\n\n\n2025-09-05 10:00\n0\n0\n0.00\n\n\n2025-09-05 11:00\n0\n0\n0.00\n\n\n2025-09-05 12:00\n0\n0\n0.00\n\n\n2025-09-05 13:00\n0\n0\n0.00\n\n\n2025-09-05 14:00\n0\n0\n0.00\n\n\n2025-09-05 15:00\n0\n0\n0.00\n\n\n2025-09-05 16:00\n0\n0\n0.00\n\n\n2025-09-05 17:00\n0\n0\n0.00\n\n\n2025-09-05 18:00\n0\n0\n0.00\n\n\n2025-09-05 19:00\n0\n0\n0.00\n\n\n2025-09-05 20:00\n0\n0\n0.00\n\n\n2025-09-05 21:00\n0\n0\n0.00\n\n\n2025-09-05 22:00\n0\n0\n0.00\n\n\n2025-09-05 23:00\n0\n0\n0.00\n\n\n2025-09-06 00:00\n0\n0\n0.00\n\n\n2025-09-06 01:00\n0\n0\n0.00\n\n\n2025-09-06 02:00\n0\n0\n0.00\n\n\n2025-09-06 03:00\n0\n0\n0.00\n\n\n2025-09-06 04:00\n0\n0\n0.00\n\n\n2025-09-06 05:00\n0\n0\n0.00\n\n\n2025-09-06 06:00\n0\n0\n0.00\n\n\n2025-09-06 07:00\n0\n0\n0.00\n\n\n2025-09-06 08:00\n0\n0\n0.00\n\n\n2025-09-06 09:00\n0\n0\n0.00\n\n\n2025-09-06 10:00\n0\n0\n0.00\n\n\n2025-09-06 11:00\n0\n0\n0.00\n\n\n2025-09-06 12:00\n0\n0\n0.00\n\n\n2025-09-06 13:00\n0\n0\n0.00\n\n\n2025-09-06 14:00\n0\n0\n0.00\n\n\n2025-09-06 15:00\n0\n0\n0.00\n\n\n2025-09-06 16:00\n0\n0\n0.00\n\n\n2025-09-06 17:00\n0\n0\n0.00\n\n\n2025-09-06 18:00\n0\n0\n0.00\n\n\n2025-09-06 19:00\n0\n0\n0.00\n\n\n2025-09-06 20:00\n0\n0\n0.00\n\n\n2025-09-06 21:00\n0\n0\n0.00\n\n\n2025-09-06 22:00\n0\n0\n0.00\n\n\n2025-09-06 23:00\n0\n0\n0.00\n\n\n2025-09-07 00:00\n0\n0\n0.00\n\n\n2025-09-07 01:00\n0\n0\n0.00\n\n\n2025-09-07 02:00\n0\n0\n0.00\n\n\n2025-09-07 03:00\n0\n0\n0.00\n\n\n2025-09-07 04:00\n0\n0\n0.00\n\n\n2025-09-07 05:00\n0\n0\n0.00\n\n\n2025-09-07 06:00\n0\n0\n0.00\n\n\n2025-09-07 07:00\n0\n0\n0.00\n\n\n2025-09-07 08:00\n0\n0\n0.00\n\n\n2025-09-07 09:00\n0\n0\n0.00\n\n\n2025-09-07 10:00\n0\n0\n0.00\n\n\n2025-09-07 11:00\n0\n0\n0.00\n\n\n2025-09-07 12:00\n0\n0\n0.00\n\n\n2025-09-07 13:00\n0\n0\n0.00\n\n\n2025-09-07 14:00\n0\n0\n0.00\n\n\n2025-09-07 15:00\n0\n0\n0.00\n\n\n2025-09-07 16:00\n0\n0\n0.00\n\n\n2025-09-07 17:00\n0\n0\n0.00\n\n\n2025-09-07 18:00\n0\n0\n0.00\n\n\n2025-09-07 19:00\n0\n0\n0.00\n\n\n2025-09-07 20:00\n0\n0\n0.00\n\n\n2025-09-07 21:00\n0\n0\n0.00\n\n\n2025-09-07 22:00\n0\n0\n0.00\n\n\n2025-09-07 23:00\n0\n0\n0.00\n\n\n2025-09-08 00:00\n0\n0\n0.00\n\n\n2025-09-08 01:00\n0\n0\n0.00\n\n\n2025-09-08 02:00\n0\n0\n0.00\n\n\n2025-09-08 03:00\n0\n0\n0.00\n\n\n2025-09-08 04:00\n0\n0\n0.00\n\n\n2025-09-08 05:00\n0\n0\n0.00\n\n\n2025-09-08 06:00\n0\n0\n0.00\n\n\n2025-09-08 07:00\n0\n0\n0.00\n\n\n2025-09-08 08:00\n0\n0\n0.00\n\n\n2025-09-08 09:00\n0\n0\n0.00\n\n\n2025-09-08 10:00\n0\n0\n0.00\n\n\n2025-09-08 11:00\n0\n0\n0.00\n\n\n2025-09-08 12:00\n0\n0\n0.00\n\n\n2025-09-08 13:00\n0\n0\n0.00\n\n\n2025-09-08 14:00\n0\n0\n0.00\n\n\n2025-09-08 15:00\n0\n0\n0.00\n\n\n2025-09-08 16:00\n0\n0\n0.00\n\n\n2025-09-08 17:00\n0\n0\n0.00\n\n\n2025-09-08 18:00\n0\n0\n0.00\n\n\n2025-09-08 19:00\n0\n0\n0.00\n\n\n2025-09-08 20:00\n0\n0\n0.00\n\n\n2025-09-08 21:00\n0\n0\n0.00\n\n\n2025-09-08 22:00\n0\n0\n0.00\n\n\n2025-09-08 23:00\n0\n0\n0.00\n\n\n2025-09-09 00:00\n0\n0\n0.00\n\n\n2025-09-09 01:00\n0\n0\n0.00\n\n\n2025-09-09 02:00\n0\n0\n0.00\n\n\n2025-09-09 03:00\n0\n0\n0.00\n\n\n2025-09-09 04:00\n0\n0\n0.00\n\n\n2025-09-09 05:00\n0\n0\n0.00\n\n\n2025-09-09 06:00\n0\n0\n0.00\n\n\n2025-09-09 07:00\n0\n0\n0.00\n\n\n2025-09-09 08:00\n0\n0\n0.00\n\n\n2025-09-09 09:00\n0\n0\n0.00\n\n\n2025-09-09 10:00\n0\n0\n0.00\n\n\n2025-09-09 11:00\n0\n0\n0.00\n\n\n2025-09-09 12:00\n0\n0\n0.00\n\n\n2025-09-09 13:00\n0\n0\n0.00\n\n\n2025-09-09 14:00\n0\n0\n0.00\n\n\n2025-09-09 15:00\n0\n0\n0.00\n\n\n2025-09-09 16:00\n0\n0\n0.00\n\n\n2025-09-09 17:00\n0\n0\n0.00\n\n\n2025-09-09 18:00\n0\n0\n0.00\n\n\n2025-09-09 19:00\n0\n0\n0.00\n\n\n2025-09-09 20:00\n0\n0\n0.00\n\n\n2025-09-09 21:00\n0\n0\n0.00\n\n\n2025-09-09 22:00\n0\n0\n0.00\n\n\n2025-09-09 23:00\n0\n0\n0.00\n\n\n2025-09-10 00:00\n0\n0\n0.00\n\n\n2025-09-10 01:00\n0\n0\n0.00\n\n\n2025-09-10 02:00\n0\n0\n0.00\n\n\n2025-09-10 03:00\n0\n0\n0.00\n\n\n2025-09-10 04:00\n0\n0\n0.00\n\n\n2025-09-10 05:00\n0\n0\n0.00\n\n\n2025-09-10 06:00\n0\n0\n0.00\n\n\n2025-09-10 07:00\n0\n0\n0.00\n\n\n2025-09-10 08:00\n0\n0\n0.00\n\n\n2025-09-10 09:00\n0\n0\n0.00\n\n\n2025-09-10 10:00\n0\n0\n0.00\n\n\n2025-09-10 11:00\n0\n0\n0.00\n\n\n2025-09-10 12:00\n0\n0\n0.00\n\n\n2025-09-10 13:00\n0\n0\n0.00\n\n\n2025-09-10 14:00\n0\n0\n0.00\n\n\n2025-09-10 15:00\n0\n0\n0.00\n\n\n2025-09-10 16:00\n0\n0\n0.00\n\n\n2025-09-10 17:00\n0\n0\n0.00\n\n\n2025-09-10 18:00\n0\n0\n0.00\n\n\n2025-09-10 19:00\n0\n0\n0.00\n\n\n2025-09-10 20:00\n0\n0\n0.00\n\n\n2025-09-10 21:00\n0\n0\n0.00\n\n\n2025-09-10 22:00\n0\n0\n0.00\n\n\n2025-09-10 23:00\n0\n0\n0.00\n\n\n2025-09-11 00:00\n0\n0\n0.00\n\n\n2025-09-11 01:00\n0\n0\n0.00\n\n\n2025-09-11 02:00\n0\n0\n0.00\n\n\n2025-09-11 03:00\n0\n0\n0.00\n\n\n2025-09-11 04:00\n0\n0\n0.00\n\n\n2025-09-11 05:00\n0\n0\n0.00\n\n\n2025-09-11 06:00\n0\n0\n0.00\n\n\n2025-09-11 07:00\n0\n0\n0.00\n\n\n2025-09-11 08:00\n0\n0\n0.00\n\n\n2025-09-11 09:00\n22\n2\n9.09\n\n\n2025-09-11 10:00\n11\n1\n9.09"
  },
  {
    "objectID": "ResearchPaper.html",
    "href": "ResearchPaper.html",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "",
    "text": "Large Language Models and automation frameworks have enabled new forms of productivity, but they rarely optimize the cognitive effort of individual users in real time. I introduce Cognitive Interaction Optimization Platform (CIOP), a multi-domain Reinforcement Learning (RL) framework designed to optimize human-computer interaction in real time. This is composed of domain-specific RL agents each focusing on a unique aspect of efficency like like Cognitive Intelligence and Real-time Adaptation.\nThis framework had two sub components:\n\nAutonmous Command Optimization Network (ACON)\nCognitive Optimization Workflow Intelligence (COWI)\n\nThis manuscript focuses on version 1.0 of Autonmous Command Optimization Network (ACON) which captures real-time user behavior, suggests optimized actions, and adapts continuously. Initial results show that ACON reduces keystrokes and mental operations, aligning with the Keystroke-Level Model (KLM). I presents an early version of the platform, with code snippets, metrics, and a roadmap towards multi-domain cognitive optimization. The version (1.0) focuses on Multi-Armed Bandit Reinforcement Learning"
  },
  {
    "objectID": "ResearchPaper.html#klm-basics",
    "href": "ResearchPaper.html#klm-basics",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "2.1 KLM Basics",
    "text": "2.1 KLM Basics\nKLM proposes following six operations. For this version of ACON, we will be disregarding the pointing devices and consider that only keyboard is the input device.\n\nK - Keystroke\nH - Homing hands on keyboard\nM - Mental preparation for action and decision making\nR - System response time. This is unique to the system\n\nEach of the elements has a time associated with it. This paper considers\n\nK - Keystroke by an average typist is \\(\\approx 40 wpm\\) is 0.28s\n\nM - Mental preparation would be \\(\\approx 1.35s\\)\n\nKeystroke-Level Model (KLM) estimates task time as:\n\\[Total ​= \\sum(nk​⋅tk​)+∑(nm​⋅tm​)+∑(nr​⋅tr​)\\]\nWhere:\n\n\\(n_k\\) : number of keystrokes, \\(t_k\\) \\(\\approx\\) 0.28\n\\(n_m\\)​: number of mental operations, \\(t_m\\) \\(\\approx\\) 1.2s\n\\(n_r\\) : number of system responses \\(t_r\\) = \\(\\approx\\) 0.3s"
  },
  {
    "objectID": "ResearchPaper.html#baseline-workflow-calculations",
    "href": "ResearchPaper.html#baseline-workflow-calculations",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "3.1 Baseline workflow & Calculations:",
    "text": "3.1 Baseline workflow & Calculations:\ncd logger\ncd src\nnvim main.rs\nThis requires:\n\nkeystrokes: \\(\\approx 30\\) [typing all commands including spaces]\nMental Ops: \\(\\approx 2\\) [recall dir names, deciding sequence cd -&gt; mkdir -&gt; cd -&gt; nvim ]\nSystem Response: \\(\\approx 3\\) [return key after each command and wait time to finish]\n\n\\(T_{manual} = (29 \\times 0.28) + (2 \\times 1.2) + (3 \\times 0.3) \\approx 8.4 + 2.4 + 0.9 \\approx 11.4s\\)"
  },
  {
    "objectID": "ResearchPaper.html#ciop-suggestions-savings",
    "href": "ResearchPaper.html#ciop-suggestions-savings",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "3.2 CIOP suggestions & Savings:",
    "text": "3.2 CIOP suggestions & Savings:\n# suggested early by bandit as it learns this folder is used frequently.\nnvim logger/src/main.rs\n\\(T_{bandit} = (23 \\times 0.28) + (1 \\times 1.2) + (1 \\times 0.3) \\approx 8.4 + 2.4 + 0.9 \\approx 7.9s\\)"
  },
  {
    "objectID": "ResearchPaper.html#final-evaluation",
    "href": "ResearchPaper.html#final-evaluation",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "3.3 Final Evaluation",
    "text": "3.3 Final Evaluation\n\nBaseline Value: \\(\\approx 11.4s\\)\nWith CIOP: \\(\\approx 7.9s\\)\n\nRoughly  31% Reduction"
  },
  {
    "objectID": "ResearchPaper.html#ciop-architecture",
    "href": "ResearchPaper.html#ciop-architecture",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "4.1 CIOP Architecture",
    "text": "4.1 CIOP Architecture\nHere is the system architecture of the CIOP with CLI agent. Future roadmap will use other domains and Meta-Agents.\n\n\n\n\n\nflowchart TD\n    subgraph CLI\n        A[User CLI Commands]\n    end\n\n    subgraph Logger\n        B[Rust Logger] --&gt; C[(rl_event_pipe)]\n        B --&gt; H[logger_cli.log]\n    end\n\n    subgraph Agent\n        D[Contextual Bandit Agent Python]\n        E[Meta-Agent future]\n    end\n\n    subgraph Metrics\n        F[Rust TUI real-time]\n        G[Python Analysis offline]\n    end\n\n    subgraph Orchestration\n        X[script.sh]\n    end\n\n    A --&gt; B\n    C --&gt; D\n    H --&gt; D\n    D --&gt; F\n    D --&gt; G\n    D -.-&gt; E\n    E --&gt; F\n    E --&gt; G\n    X --&gt; A\n    X --&gt; B\n    X --&gt; D\n    X --&gt; F\n    X --&gt; G"
  },
  {
    "objectID": "ResearchPaper.html#ciop-flow-chart",
    "href": "ResearchPaper.html#ciop-flow-chart",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "4.2 CIOP Flow chart",
    "text": "4.2 CIOP Flow chart\n\n\n\n\n\nflowchart TD\n    subgraph User\n        A1[Manual Typing] --&gt;|logs| L[logger_cli.log]\n        A2[Bandit Suggest] --&gt;|accept/cancel| M[.cli_bandit_accepts]\n    end\n\n    subgraph Logger\n        L --&gt;|command_seen| J[.cli_bandit_metrics.jsonl]\n        A2 --&gt;|suggestion_shown| J\n        A2 --&gt;|suggestion_accepted| J\n    end\n\n    subgraph PythonAgent[\"Python Agent\"]\n        J --&gt;|command_seen discovery| B[cli_bandit_agent.py]\n        M --&gt;|reward updates| B\n        B --&gt;|save model| N[.cli_bandit_model.json]\n        B --&gt;|log q_updates| J\n    end\n\n    subgraph RustTUI[\"Rust TUI\"]\n        J --&gt; R[metrics.rs viewer]\n    end\n\n    subgraph PythonAnalysis[\"Python Analysis\"]\n        J --&gt; P1[metrics_analysis.py]\n        P1 --&gt;|KLM savings & plots| IMG[image/*.png]\n    end\n\n    subgraph MetaAgent[\"Meta Agent\"]\n        J --&gt; P2[meta_agent.py]\n    end\n\n    User --&gt;|test script| S[script.sh]\n    S --&gt; Logger\n    S --&gt; PythonAgent\n    S --&gt; RustTUI\n    S --&gt; PythonAnalysis\n    S --&gt; MetaAgent\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nUser commands are categorized as Manual Typing"
  },
  {
    "objectID": "ResearchPaper.html#ciop-sequence-diagram",
    "href": "ResearchPaper.html#ciop-sequence-diagram",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "4.3 CIOP Sequence Diagram",
    "text": "4.3 CIOP Sequence Diagram\n\n\n\n\n\nsequenceDiagram\n  participant User as User (CLI)\n  participant Logger as Rust Logger\n  participant Pipe as rl_event_pipe\n  participant Agent as Bandit Agent (Python)\n  participant Metrics as Rust TUI\n  participant Analysis as Python Metrics\n\n  User-&gt;&gt;Logger: Type command\n  Logger-&gt;&gt;Pipe: Write event (command_seen)\n  Logger-&gt;&gt;Metrics: Update real-time display\n  Logger-&gt;&gt;Analysis: Log command to metrics.jsonl\n\n  User-&gt;&gt;Agent: Invoke suggestion (Ctrl-B)\n  Agent-&gt;&gt;Pipe: Reads context (cwd, history)\n  Agent-&gt;&gt;User: Suggest top-k commands\n  User-&gt;&gt;Agent: Accept suggestion\n  Agent-&gt;&gt;Metrics: Log suggestion_accepted\n  Agent-&gt;&gt;Analysis: Log q_update & KLM savings\n\n    Note over Metrics,Analysis: Metrics shown real-time in Rust TUI&lt;br&gt;Offline analysis & plots with Python"
  },
  {
    "objectID": "ResearchPaper.html#folder-structure",
    "href": "ResearchPaper.html#folder-structure",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "6.1 Folder structure",
    "text": "6.1 Folder structure\nacon\n├── agent\n│   ├── cli_agent/\n│   ├── meta_agent/\n├── Cargo.toml\n├── logger\n│   └── src/\n│   ├── data/\n│   ├── logger.toml\n│   ├── Cargo.toml\n├── script.sh\n├── README.md"
  },
  {
    "objectID": "ResearchPaper.html#cli-and-arguments",
    "href": "ResearchPaper.html#cli-and-arguments",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "6.2 CLI and Arguments",
    "text": "6.2 CLI and Arguments\nUsage: logger &lt;COMMAND&gt;\n\nCommands:\n  start    Start unified logger\n  tail     Tail live events from the pipe\n  search   Search module logs with ripgrep\n  fzf      Browse module logs with fzf\n  metrics  Real time Metrics\n  help     Print this message\n\nOptions:\n  -h, --help     Print help\n  -V, --version  Print version"
  },
  {
    "objectID": "ResearchPaper.html#toml-extensible-configuration",
    "href": "ResearchPaper.html#toml-extensible-configuration",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "6.3 TOML Extensible configuration",
    "text": "6.3 TOML Extensible configuration\n[sources]\ncli=true\n\n[output]\npipe_path = \"data/rl_event_pipe\"\nbackup_file = \"data/rl_logs.jsonl\"\n\n[cli]\nbuffer_path = \".cli_command_buffer\"\ncapture_fields = [ \"time\", \"session_id\", \"cwd\", \"command\", \"keystroke_count\", \"exit_code\"]"
  },
  {
    "objectID": "ResearchPaper.html#zsh-command-logging",
    "href": "ResearchPaper.html#zsh-command-logging",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "6.4 zsh command logging",
    "text": "6.4 zsh command logging\nprecmd() { \nlocal RET=$? # check for status 0 = successful\nlocal TS=$(date -Iseconds)\n# last command from history\nlocal CMD=$(fc -ln -1)\n# encode to base64\nlocal CMD_B64=$(printf \"%s\" \"$CMD\" | base64 | tr -d '\\n') \n# enable this code for recording the commands\nprintf \"%s\\t%s\\t%s\\t%s\\n\" \"$TS\" \"$PWD\" \"$RET\" \"$CMD_B64\" &gt;&gt; ~/.cli_command_buffer\n}"
  },
  {
    "objectID": "ResearchPaper.html#events-rl_event_pipe.",
    "href": "ResearchPaper.html#events-rl_event_pipe.",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "6.5 Events rl_event_pipe.",
    "text": "6.5 Events rl_event_pipe.\n    if Path::new(pipe_path).exists() {\n        match OpenOptions::new()\n            .write(true)\n            .custom_flags(libc::O_NONBLOCK) // don’t block if no reader\n            .open(pipe_path)\n        {\n            Ok(mut pipe) =&gt; {\n                if let Err(e) = writeln!(pipe, \"{}\", json_str) {\n                    if e.kind() != std::io::ErrorKind::BrokenPipe {\n                eprintln!(\"Failed to write to pipe: {}\", e);\n            }\n    ...\n}  \n👀 Tailing cli events from data/rl_event_pipe\n{\"data\":{\"command\":\"ll\",\"cwd\":\"/projects/ciop/logger\",\"exit_code\":0,\n\"keystroke_count\":2,\"session_id\":1,\"time\":\"2022-09-17T10:22:48.159270Z\"},\n\"source\":\"cli\"}\n{\"event\": \"suggestion_accepted\", \"suggestion_id\": \"ae2516bc\", \"source\": \"cli\", \"text\": \"pwd\", \"cwd\": \"ciop/logger\", \"seen\": true, \"accepted\": true, \"timestamp\": \"2025-09-17T03:42:22.603479Z\", \"keystrokes\": 3, \"mental_ops\": 1, \"predicted_time\": 2.04}\n{\"event\": \"q_update\", \"source\": \"cli\", \"state\": \"/Users/rv/Documents/projects/ciop/logger\", \"action\": \"pwd\", \"reward\": 1.0, \"old_q\": 1.0, \"new_q\": 1.0, \"count\": 6, \"timestamp\": \"2025-09-17T03:42:22.604159Z\", \"keystrokes\": 3, \"mental_ops\": 1, \"predicted_time\": 2.04}\n{\"cwd\":\"ciop/logger\",\"event\":\"command_seen\",\"exit_code\":0,\"keystrokes\":14,\"source\":\"cli\",\"text\":\"bandit-suggest\",\"timestamp\":\"2025-09-17T03:42:24.467725+00:00\"}"
  },
  {
    "objectID": "ResearchPaper.html#python-bandit-agent",
    "href": "ResearchPaper.html#python-bandit-agent",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "6.6 Python bandit agent:",
    "text": "6.6 Python bandit agent:\n\n6.6.1 Consume events.\nprint(\"Listening for events...\")\nfor event in stream_events():\n    print(\"Received:\", event)\n\n\n6.6.2 Loading Model\n agent = load_agent_or_default(MODEL_PATH)\n    \n    # generate suggestion id\n    suggestion_id = str(uuid.uuid4())[:8]  # Short unique ID for this suggestion session\n    # 1) Learn from previous accepts first\n    processed = agent.update_from_accept_log(ACCEPT_LOG)\n\n\n6.6.3 Epsilon Greedy\nif explore:\n    a = random.choice(self.actions)\n    strategy = \"explore\"\nelse:\n    # choose best by Q\n    a = max(self.q_values[state], key=self.q_values[state].get)\n    strategy = \"exploit\"\n\n\n6.6.4 fzf (Python)\ndef run_fzf(options):\n    if not options:\n        return \"\"\n    # call fzf, return stdout (selected line) as str\n    proc = subprocess.run([\"fzf\", \"--height\", \"40%\"], input=\"\\n\".join(options).encode(), capture_output=True)\n    return proc.stdout.decode().strip()\n\n\n6.6.5 fzf (Rust)\nlet status = Command::new(\"sh\")\n            .arg(\"-lc\")\n            .arg(format!(\"cat {f} | fzf --no-sort --tac --preview 'echo {{}}'\", f = log_file))\n            .status()\n            .expect(\"Failed to run fzf via shell\");\n        if !status.success() {\n            eprintln!(\"fzf exited with non-zero.\");\n        }\n\n\n\n6.6.6. fzf (zsh - Ctrl-b shortcut)\nbandit-suggest() {\n  CMD=$(python3 ciop/agent/cli_agent/bandit_suggest.py) \n  if [ -n \"$CMD\" ]; then\n    # run command printed by the script\n    echo \"Bandit suggests: $CMD\"\n    eval \"$CMD\"\n  fi\n}\n# bind Ctrl-b to the function (zsh)\nbindkey -s '^b' 'bandit-suggest\\n'\n\n\n6.6.7 Bandit Suggestions"
  },
  {
    "objectID": "ResearchPaper.html#real-time-rust-tui",
    "href": "ResearchPaper.html#real-time-rust-tui",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "7.1 Real-time Rust TUI",
    "text": "7.1 Real-time Rust TUI\nThis is a real time metrics run using\n$&gt; ciop --metrics\n┌ Info ───────────────────────────────────────────────────────────────────────┐\n│Metrics viewer (press 'q' to quit, 'r' to reset)                             │\n└─────────────────────────────────────────────────────────────────────────────┘\n┌Bandit Metrics Summary───────────────────────────────────────────────────────┐\n│Seen: 429   Accepted: 30   AcceptRate: 6.99%   UniqueActions: 20             │\n└─────────────────────────────────────────────────────────────────────────────┘\n┌Keystroke-Level Model (KLM)──────────────────────────────────────────────────┐\n│Manual: 526 keystrokes, 54 mental, 54 sys → 228.28s                          │\n└─────────────────────────────────────────────────────────────────────────────┘\n┌Recent Metrics───────────────────────────────────────────────────────────────┐\n│2025-09-17T15:44:57.586287Z | cli | q_update | -                             │\n│   pwd                                                                       │\n│2025-09-17T15:44:57.586542Z | cli | q_update | -                             │\n│   clear                                                                     │                         \n│2025-09-17T15:44:57.588184Z | cli | command_seen | ciop/agent/cli_agent.     │\n│   clear                                                                     │\n│2025-09-17T15:44:57.588251Z | cli | command_seen | ciop/agent/cli_agent      │\n│ ...                                                                         │\n└─────────────────────────────────────────────────────────────────────────────┘\n┌Raw Log (debug view)──────────────────────────────────────────────────────────┐\n│{\"event\":\"q_update\",\"source\": \"cli\",\"state\": \"ciop/agent/cli_agent\",\"action\"  │\n│{\"event\":\"q_update\",\"source\": \"cli\",\"state\": \"ciop/agent/cli_agent\", \"action\":│\n│{\"event\":\"q_update\",\"source\": \"cli\",\"state\": \"ciop\", \"action\": \"pw\", \"reward\" │\n..."
  },
  {
    "objectID": "ResearchPaper.html#acceptance-rate-over-time",
    "href": "ResearchPaper.html#acceptance-rate-over-time",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "7.2 Acceptance Rate Over Time",
    "text": "7.2 Acceptance Rate Over Time"
  },
  {
    "objectID": "ResearchPaper.html#unique-actions-learned",
    "href": "ResearchPaper.html#unique-actions-learned",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "7.3 Unique Actions Learned",
    "text": "7.3 Unique Actions Learned"
  },
  {
    "objectID": "ResearchPaper.html#q-value-by-action",
    "href": "ResearchPaper.html#q-value-by-action",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "7.4 Q-Value by Action",
    "text": "7.4 Q-Value by Action"
  },
  {
    "objectID": "ResearchPaper.html#final-q-values",
    "href": "ResearchPaper.html#final-q-values",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "7.5 Final Q-Values",
    "text": "7.5 Final Q-Values"
  },
  {
    "objectID": "ResearchPaper.html#q-value-vs-baseline",
    "href": "ResearchPaper.html#q-value-vs-baseline",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "7.6 Q-Value vs Baseline",
    "text": "7.6 Q-Value vs Baseline"
  },
  {
    "objectID": "ResearchPaper.html#summary-metrics",
    "href": "ResearchPaper.html#summary-metrics",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "7.7 Summary Metrics",
    "text": "7.7 Summary Metrics\n| Metric              | Value |\n|---------------------|-------|\n| Total Seen          | 430   |\n| Total Accepted      | 30    |\n| Acceptance Rate (%) | 9.09  |\n| Unique Actions      | 22    |"
  },
  {
    "objectID": "ResearchPaper.html#metrics-daily",
    "href": "ResearchPaper.html#metrics-daily",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "7.8 Metrics (Daily)",
    "text": "7.8 Metrics (Daily)\n| Time              | Seen | Accepted | Acceptance Rate (%) |\n|-------------------|------|----------|---------------------|\n| 2025-08-28 00:00  | 33   | 3  | 9.09                      |\n...\n| 2025-09-11 00:00  | 33   | 3  | 9.09                      |\n...\n| 2025-09-13 00:00  | 0    | 0  | 0.00                      |\n| 2025-09-14 00:00  | 0    | 0  | 0.00                      |\n| 2025-09-16 00:00  | 196  | 16 | 8.16                      |\n| 2025-09-17 00:00  | 158  | 8  | 5.06                      |\n..."
  },
  {
    "objectID": "ResearchPaper.html#metrics-hourly",
    "href": "ResearchPaper.html#metrics-hourly",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "7.9 Metrics (Hourly)",
    "text": "7.9 Metrics (Hourly)\n\n| Time              | Seen | Accepted | Acceptance Rate (%) |\n|-------------------|------|----------|---------------------|\n| 2025-08-28 07:00 | 33    | 3        | 9.09                |\n| 2025-09-16 00:00 | 0     | 0        | 0.00                |\n| 2025-09-16 04:00 | 44    | 4        | 9.09                |\n...\n| 2025-09-16 05:00 | 53    | 3        | 5.66                |\n| 2025-09-16 06:00 | 22    | 2        | 9.09                |\n| 2025-09-16 07:00 | 77    | 7        | 9.09                |\n| 2025-09-16 23:00 | 0     | 0        | 0.00                |\n...\n| 2025-09-17 02:00 | 43    | 3        | 6.98                |\n| 2025-09-17 03:00 | 95    | 5        | 5.26                |\n| 2025-09-17 05:00 | 20    | 0        | 0.00                |\n..."
  },
  {
    "objectID": "ResearchPaper.html#klm-savings",
    "href": "ResearchPaper.html#klm-savings",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "7.10 KLM Savings",
    "text": "7.10 KLM Savings\n=== KLM Savings Summary ===\nmanual_total_time   : 155.76\nbandit_total_time   : 52.8\ntime_saved          : 102.96\nnum_manual          : 29\nnum_suggestions     : 30"
  },
  {
    "objectID": "ResearchPaper.html#klm-hourly",
    "href": "ResearchPaper.html#klm-hourly",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "7.11 KLM Hourly",
    "text": "7.11 KLM Hourly"
  },
  {
    "objectID": "ResearchPaper.html#klm-daily",
    "href": "ResearchPaper.html#klm-daily",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "7.12 KLM Daily",
    "text": "7.12 KLM Daily"
  },
  {
    "objectID": "ResearchPaper.html#related-work-2",
    "href": "ResearchPaper.html#related-work-2",
    "title": "Multi-Domain Cognitive Optimization via Real-Time Reinforcement Learning",
    "section": "13.1 Related work",
    "text": "13.1 Related work\nPrevious research on cognitive optimization (Paul Holleis 2025) has shown\n\nKeystroke Level Model MultiArm Bandit\n\nHill, David. 1984. “A Bibliography to Human-Computer Interaction: Concepts, Methods and Problems.” October 1984.\n\n\nPaul Holleis, Heinrich Hussmann, Friederike Otto. 2025. “CIOP ACON.” September 16, 2025. https://dl.acm.org/doi/10.1145/1240624.1240851."
  },
  {
    "objectID": "ciop-v1/Overview.html",
    "href": "ciop-v1/Overview.html",
    "title": "qpaper",
    "section": "",
    "text": "1 + 1\n\n2"
  },
  {
    "objectID": "ciop-v1/manuscript.html",
    "href": "ciop-v1/manuscript.html",
    "title": "Autonomous Command Optimization Network",
    "section": "",
    "text": "I present a learning framework that models command-line usage as a contextual bandit problem. My system, ACON (Autonomous Command Optimization Network), captures real CLI activity using a Rust logger, streams events into a Python-based bandit agent, and integrates with an interactive fzf interface for real-time suggestions. This work demonstrates a novel application of contextual bandits for human productivity optimization."
  },
  {
    "objectID": "ciop-v1/manuscript.html#abstract",
    "href": "ciop-v1/manuscript.html#abstract",
    "title": "Autonomous Command Optimization Network",
    "section": "",
    "text": "I present a learning framework that models command-line usage as a contextual bandit problem. My system, ACON (Autonomous Command Optimization Network), captures real CLI activity using a Rust logger, streams events into a Python-based bandit agent, and integrates with an interactive fzf interface for real-time suggestions. This work demonstrates a novel application of contextual bandits for human productivity optimization."
  },
  {
    "objectID": "ciop-v1/manuscript.html#introduction",
    "href": "ciop-v1/manuscript.html#introduction",
    "title": "Autonomous Command Optimization Network",
    "section": "1. Introduction",
    "text": "1. Introduction\n\nCLI is powerful but has steep learning curve.\nExisting tools: history, autocomplete, fzf are reactive, not adaptive."
  },
  {
    "objectID": "ciop-v1/manuscript.html#motivation",
    "href": "ciop-v1/manuscript.html#motivation",
    "title": "Autonomous Command Optimization Network",
    "section": "2. Motivation",
    "text": "2. Motivation\nCan we learn from the user and adapt proactively?"
  },
  {
    "objectID": "ciop-v1/manuscript.html#contribution",
    "href": "ciop-v1/manuscript.html#contribution",
    "title": "Autonomous Command Optimization Network",
    "section": "3. Contribution:",
    "text": "3. Contribution:\nBandit-based CLI optimization with real-time interactive feedback."
  },
  {
    "objectID": "ciop-v1/manuscript.html#background-related-work",
    "href": "ciop-v1/manuscript.html#background-related-work",
    "title": "Autonomous Command Optimization Network",
    "section": "4. Background & Related Work",
    "text": "4. Background & Related Work\n\n2.1 Command-line productivity challenges\n2.2 Reinforcement Learning vs Bandits\n2.3 Contextual Bandit formulation"
  },
  {
    "objectID": "ciop-v1/manuscript.html#problem-formulation",
    "href": "ciop-v1/manuscript.html#problem-formulation",
    "title": "Autonomous Command Optimization Network",
    "section": "3. Problem Formulation",
    "text": "3. Problem Formulation\n\nYour specific use case\nMathematical formulation"
  },
  {
    "objectID": "ciop-v1/manuscript.html#methodology",
    "href": "ciop-v1/manuscript.html#methodology",
    "title": "Autonomous Command Optimization Network",
    "section": "4. Methodology",
    "text": "4. Methodology\n\nAlgorithm design\nImplementation architecture"
  },
  {
    "objectID": "ciop-v1/manuscript.html#implementation-details",
    "href": "ciop-v1/manuscript.html#implementation-details",
    "title": "Autonomous Command Optimization Network",
    "section": "5. Implementation Details",
    "text": "5. Implementation Details\n\nRust components (with code blocks)\nPython AI pipeline\nSystem architecture diagrams"
  },
  {
    "objectID": "ciop-v1/manuscript.html#experimental-setup",
    "href": "ciop-v1/manuscript.html#experimental-setup",
    "title": "Autonomous Command Optimization Network",
    "section": "6. Experimental Setup",
    "text": "6. Experimental Setup"
  },
  {
    "objectID": "ciop-v1/manuscript.html#results-analysis",
    "href": "ciop-v1/manuscript.html#results-analysis",
    "title": "Autonomous Command Optimization Network",
    "section": "7. Results & Analysis",
    "text": "7. Results & Analysis"
  },
  {
    "objectID": "ciop-v1/manuscript.html#discussion-future-work",
    "href": "ciop-v1/manuscript.html#discussion-future-work",
    "title": "Autonomous Command Optimization Network",
    "section": "8. Discussion & Future Work",
    "text": "8. Discussion & Future Work\n\nLimitations of v1.0\nPlanned improvements for v2.0"
  },
  {
    "objectID": "ciop-v1/manuscript.html#conclusion",
    "href": "ciop-v1/manuscript.html#conclusion",
    "title": "Autonomous Command Optimization Network",
    "section": "9. Conclusion",
    "text": "9. Conclusion"
  },
  {
    "objectID": "ciop-v1/manuscript.html#references",
    "href": "ciop-v1/manuscript.html#references",
    "title": "Autonomous Command Optimization Network",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "ciop-v1/manuscript.html#appendix-optional",
    "href": "ciop-v1/manuscript.html#appendix-optional",
    "title": "Autonomous Command Optimization Network",
    "section": "Appendix (Optional)",
    "text": "Appendix (Optional)\n\nAdditional code snippets\nExtended results"
  },
  {
    "objectID": "images/metrics_timeseries_D.html",
    "href": "images/metrics_timeseries_D.html",
    "title": "Research Home",
    "section": "",
    "text": "Time\nSeen\nAccepted\nAcceptance Rate (%)\n\n\n\n\n2025-08-28 00:00\n33\n3\n9.09\n\n\n2025-08-29 00:00\n0\n0\n0.00\n\n\n2025-08-30 00:00\n0\n0\n0.00\n\n\n2025-08-31 00:00\n0\n0\n0.00\n\n\n2025-09-01 00:00\n0\n0\n0.00\n\n\n2025-09-02 00:00\n0\n0\n0.00\n\n\n2025-09-03 00:00\n0\n0\n0.00\n\n\n2025-09-04 00:00\n0\n0\n0.00\n\n\n2025-09-05 00:00\n0\n0\n0.00\n\n\n2025-09-06 00:00\n0\n0\n0.00\n\n\n2025-09-07 00:00\n0\n0\n0.00\n\n\n2025-09-08 00:00\n0\n0\n0.00\n\n\n2025-09-09 00:00\n0\n0\n0.00\n\n\n2025-09-10 00:00\n0\n0\n0.00\n\n\n2025-09-11 00:00\n33\n3\n9.09"
  },
  {
    "objectID": "images/metrics_summary.html",
    "href": "images/metrics_summary.html",
    "title": "Research Home",
    "section": "",
    "text": "Metric\nValue\n\n\n\n\nTotal Seen\n66\n\n\nTotal Accepted\n6\n\n\nAcceptance Rate (%)\n9.09\n\n\nUnique Actions\n12"
  }
]